{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARE 106 Summer Session II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "This homework will be due on **September 2nd, at 4:10pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSID: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please put your name and SSID in the corresponding cells above.\n",
    "\n",
    "The homework is worth 13.5 points.\n",
    "\n",
    "For each of the following questions, show as much of your steps as you can (without going overboard). If you end up getting the wrong answer, but we spot where you made a mistake in the algebra, partial credit will be more readily given. If you only put the final answer, you will be marked either right or wrong.\n",
    "\n",
    "Answer questions in the correct cell. For problems where you have to input math, make sure that you know that it's a markdown cell (It won't have a `In: []` on the left) and make sure you run the cell by either pressing `Ctrl + Enter` or going to `Cell -> Run Cell`. Alternatively, write all your answers and then go to `Cell -> Run All Cells` after you're done. \n",
    "\n",
    "Please ignore cells that read `\\pagebreak`. These are so your document converts to PDF in a way that will make it possible to grade your homework. Ignore them and only write your answers where it is specified.\n",
    "\n",
    "**When you are finished export your homework to a PDF by going to `File -> Download as -> PDF`.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Unbiasedness \n",
    "\n",
    "For the following question, assume that we have a population model:\n",
    "\n",
    "$$\n",
    "Y_i = \\mu + \\varepsilon_i\n",
    "$$ \n",
    "\n",
    "where $E(\\varepsilon_i) = 0$.\n",
    "\n",
    "We're able to get a sample of $N$ observations of $Y_i$. For the following linear estimators of $\\mu$, find whether or not they are unbiased estimators of $Y_i$.\n",
    "\n",
    "- a. $\\frac{1}{N}\\sum_i^N Y_i$\n",
    "- b. $\\sum_i^N Y_i$\n",
    "- c. $Y_3$\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "- a. $E( \\frac{1}{N}\\sum_i^N Y_i)= \\frac{1}{N}E(\\sum_i^N Y_i) =  \\frac{1}{N}\\sum_i^N E(Y_i) = \\frac{1}{N}\\sum_i^N \\mu = \\frac{1}{N} \\cdot N \\cdot \\mu = \\mu$. Unbiased\n",
    "- b. $E(\\sum_i^N Y_i) = \\sum_i^N E(Y_i) = \\sum_i^N \\mu  = N\\cdot \\mu$ Biased.\n",
    "- c. $E(Y_3) = \\mu$ Unbiased.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: More Unbiasedness\n",
    "\n",
    "\n",
    "Now suppose that the population model is:\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "where $X_i$ is some data and is treated as *given* (i.e. not a random variable). Once again, $E(\\varepsilon_i)=0$. Assume that all Gauss-Markov assumptions are satisfied.\n",
    "\n",
    "We're able to get a sample of $N$ observations of $Y_i$. For the following linear estimators of $\\beta_1$, answer the following questions.\n",
    "\n",
    "- a. What is the expected value of: $\\sum_i^N k_i Y_i$, where $k_i$ is some weight for every observation, which is not dependent on $Y_i$ (not necessarily the OLS weight!!). Also do not bring in the expectation operator, just leave the operator outside the expression.\n",
    "- b. What has to be true in order for the estimator in a. to be unbiased? \n",
    "- c. What Gauss-Markov assumption do we use to make sure that $\\sum_i^N k_i \\varepsilon_i=0$ in the OLS case?\n",
    "- d. What is the expected value of: $\\frac{1}{N} \\sum_i^N Y_i$. Let $E(X_i)=\\mu_x$\n",
    "- e. What needs to be true, so that the estimator in d. is unbiased?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "- a. $E(\\sum_i^N k_i Y_i) = E(\\sum_i^N k_i (\\beta_0 + \\beta_1 X_i + \\varepsilon_i)) = E(\\beta_0 \\sum_i^N k_i +  \\beta_1 \\sum_i^N k_i X_i + \\sum_i^N k_i \\varepsilon_i)$\n",
    "- b. We need $\\sum_i^N k_i = 0$, $\\sum_i^N k_i X_i=1$, and $\\sum_i^N k_i \\varepsilon_i=0$\n",
    "- c. CR 5: exogeneity of the $X_i$ variables.\n",
    "- d. $E(\\frac{1}{N} \\sum_i^N Y_i) = E(\\frac{1}{N} \\sum_i^N(\\beta_0 + \\beta_1 X_i + \\varepsilon_i))= \\frac{1}{N} \\sum_i^N E(\\beta_0) + \\beta_1 \\frac{1}{N}\\sum_i^N E(X_i) + \\frac{1}{N} \\sum_i^N E(\\varepsilon_i)= \\beta_0 + \\beta_1 \\mu_x$\n",
    "- e. $\\beta_0 =0$ and $\\mu_x=1$.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Variance of an Estimator\n",
    "\n",
    "For the following question, assume that we have two possible population models:\n",
    "\n",
    "$$\n",
    "Y_i = \\mu + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "where $E(\\varepsilon_i) = 0$.\n",
    "\n",
    "We're able to get a sample of $N$ observations of $Y_i$. For the following linear estimators of $\\mu$, find the variance of the estimator. \n",
    "\n",
    "**Note: It need not be the case that $Cov(\\varepsilon_i, \\varepsilon_j)=0$ or that $Var(\\varepsilon_i) = \\sigma^2$, unless explicitly stated.**\n",
    "\n",
    "- a. $\\frac{1}{N}\\sum_i^N Y_i$, with $Cov(\\varepsilon_i, \\varepsilon_j)=0$ and $Var(\\varepsilon_i) = \\sigma^2$\n",
    "- b. $\\frac{1}{N}\\sum_i^N Y_i$, with $Cov(\\varepsilon_i, \\varepsilon_j)=0$ and $Var(\\varepsilon_i) = \\sigma_i^2$. **Note the difference!**\n",
    "- c. $\\frac{Y_1 + Y_2}{2}$, with $Cov(\\varepsilon_i, \\varepsilon_j)\\neq0$ and $Var(\\varepsilon_i) = \\sigma^2$\n",
    "- d. Would the estimator from c. be an unbiased estimator of $\\sigma^2$?\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "- a. $Var(\\frac{1}{N}\\sum_i^N Y_i)=\\frac{1}{N^2} \\sum_i^N Var(Y_i) = \\frac{1}{N^2} N \\sigma^2 = \\frac{1}{N} \\sigma^2$\n",
    "- b. $Var(\\frac{1}{N}\\sum_i^N Y_i)=\\frac{1}{N^2} \\sum_i^N Var(Y_i) = \\frac{1}{N^2} \\sum_i^N \\sigma^2_i$\n",
    "- c. $Var(\\frac{Y_1 + Y_2}{2})= Var(\\frac{1}{2} Y_1) + Var(\\frac{1}{2} Y_2) + 2 Cov(\\frac{1}{2} Y_1, \\frac{1}{2} Y_2)= \\frac{1}{4} \\sigma^2 + \\frac{1}{4} \\sigma^2 + \\frac{1}{2} Cov(Y_1, Y_2)=\\frac{1}{2} \\sigma^2 + \\frac{1}{2} Cov(Y_1, Y_2)$\n",
    "- d. No, because there is a non-zero covariance term and $\\sigma^2$ is being multiplied by $\\frac{1}{2}$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Showing Unbiasedness with Data\n",
    "\n",
    "For this question, we're going to create some random data, and see how well the OLS estimator is able to estimate this data.\n",
    "\n",
    "Suppose we have a population model:\n",
    "\n",
    "$$\n",
    "Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "First, we're going to create random data for $Y_i$ and $X_i$. This will involve using the `random` library in Python. \n",
    "\n",
    "This the code to generate the random data and construct our population model. **Note that we in constructing this population model, we are following the Gauss Markov assumptions**:\n",
    "\n",
    "```python\n",
    "## imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "## This is for making graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## define error\n",
    "## makes 1000 normally distributed observations with mean 0 and standard deviaion 1\n",
    "epsilon = np.random.normal(0,1, 1000) \n",
    "\n",
    "## define X data\n",
    "## makes 1000 normally distributed observations with mean 3 and standard deviaion 2\n",
    "X = np.random.normal(3, 2, 1000)\n",
    "\n",
    "## Define population parameters\n",
    "beta_0 = 2\n",
    "beta_1 = .5\n",
    "\n",
    "## Define Y data\n",
    "Y = beta_0 +  beta_1*X + epsilon\n",
    "\n",
    "## Put it all in a pandas dataframe\n",
    "df = pd.DataFrame({'Y': Y,\n",
    "             'X': X})\n",
    "             \n",
    "```\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Before running the code, look at the code. What Gauss-Markov assumption is responsible for the fact that $\\varepsilon_i$ comes from a *normal distribution*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "CR4- normally distributed errors"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Before running the code, What Gauss-Markov assumption is responsible for the fact that $\\varepsilon_i$ comes from the fact that $\\varepsilon_i$ comes from a distribution whose variance (or in this case standard deviation) that doesn't change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "CR3- homoskedasticity"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Run the regression of $Y$ on $X$. \n",
    "\n",
    "What is the estimate? What is the normalized z-score for this estimate? Put your anwer in a print statement f-string (Put this print statement before the `summary()` call so both show up). \n",
    "\n",
    "**Hint: you know what the population parameter actually is.**\n",
    "\n",
    "**Hint: You can either write down the parameters from the regression or use `results.params['X']` for $\\hat{b}_1$ and `results.bse['X']` for the standard error of $\\hat{b}_1$.**\n",
    "\n",
    "**Note: By normalized z-score, I mean the transformation that makes the estimate in terms of a Normal distribution of mean 0 and variance 1.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T04:15:59.403116Z",
     "start_time": "2019-08-28T04:15:59.369574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The normalized z-score is 65.10924550509961\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.833</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.832</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4966.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 27 Aug 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:15:59</td>     <th>  Log-Likelihood:    </th> <td> -3204.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1000</td>      <th>  AIC:               </th> <td>   6413.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   998</td>      <th>  BIC:               </th> <td>   6422.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -3.1819</td> <td>    0.339</td> <td>   -9.390</td> <td> 0.000</td> <td>   -3.847</td> <td>   -2.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>         <td>    6.5762</td> <td>    0.093</td> <td>   70.467</td> <td> 0.000</td> <td>    6.393</td> <td>    6.759</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>844.815</td> <th>  Durbin-Watson:     </th> <td>   1.990</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>28824.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 3.688</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>28.247</td>  <th>  Cond. No.          </th> <td>    6.87</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.833\n",
       "Model:                            OLS   Adj. R-squared:                  0.832\n",
       "Method:                 Least Squares   F-statistic:                     4966.\n",
       "Date:                Tue, 27 Aug 2019   Prob (F-statistic):               0.00\n",
       "Time:                        21:15:59   Log-Likelihood:                -3204.3\n",
       "No. Observations:                1000   AIC:                             6413.\n",
       "Df Residuals:                     998   BIC:                             6422.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -3.1819      0.339     -9.390      0.000      -3.847      -2.517\n",
       "X              6.5762      0.093     70.467      0.000       6.393       6.759\n",
       "==============================================================================\n",
       "Omnibus:                      844.815   Durbin-Watson:                   1.990\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            28824.463\n",
       "Skew:                           3.688   Prob(JB):                         0.00\n",
       "Kurtosis:                      28.247   Cond. No.                         6.87\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Put your answer in this cell.\n",
    "\n",
    "## imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "## This is for making graphs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## define error\n",
    "## makes 1000 normally distributed observations with mean 0 and standard deviaion 1\n",
    "epsilon = np.random.normal(0,1, 1000) \n",
    "\n",
    "## define X data\n",
    "## makes 1000 normally distributed observations with mean 3 and standard deviaion 2\n",
    "X = np.random.normal(3, 2, 1000)\n",
    "\n",
    "## Define population parameters\n",
    "beta_0 = 2\n",
    "beta_1 = .5\n",
    "\n",
    "## Define Y data\n",
    "Y = beta_0 +  beta_1*X + epsilon\n",
    "\n",
    "## Put it all in a pandas dataframe\n",
    "df = pd.DataFrame({'Y': Y,\n",
    "             'X': X})\n",
    "\n",
    "## Running regression\n",
    "\n",
    "mod = sm.ols(\"Y ~ X\", data=df)\n",
    "results = mod.fit()\n",
    "\n",
    "\n",
    "print(f\"The normalized z-score is {(results.params['X']-0.5)/results.bse['X']}\")\n",
    "\n",
    "results.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Now let's get a sample of this and data and run our regression on it. To do this, use the `sample` method on the `df` dataframe:\n",
    "\n",
    "```python\n",
    "df.sample(n=<number>, replace=True)\n",
    "```\n",
    "\n",
    "We set `replace=True`, so that we can sample observations with replacement (this is more important if we keep taking random samples).\n",
    "\n",
    "Sample 100 observations with replacement from `df` and call this `sample_df`. \n",
    "\n",
    "Run the regression of Y on X with the sample data. Run it a few times and see how it changes (you do need to need rerun the previous cells if you rerun this one a few times. That's because the initial data has already been created.)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T00:48:53.762312Z",
     "start_time": "2019-08-24T00:48:53.728394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.542</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   115.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 23 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>2.74e-18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:48:53</td>     <th>  Log-Likelihood:    </th> <td> -136.39</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   276.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    98</td>      <th>  BIC:               </th> <td>   282.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.0240</td> <td>    0.160</td> <td>   12.663</td> <td> 0.000</td> <td>    1.707</td> <td>    2.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X</th>         <td>    0.5187</td> <td>    0.048</td> <td>   10.760</td> <td> 0.000</td> <td>    0.423</td> <td>    0.614</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.283</td> <th>  Durbin-Watson:     </th> <td>   2.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.527</td> <th>  Jarque-Bera (JB):  </th> <td>   0.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.200</td> <th>  Prob(JB):          </th> <td>   0.657</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.202</td> <th>  Cond. No.          </th> <td>    5.88</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.542\n",
       "Model:                            OLS   Adj. R-squared:                  0.537\n",
       "Method:                 Least Squares   F-statistic:                     115.8\n",
       "Date:                Fri, 23 Aug 2019   Prob (F-statistic):           2.74e-18\n",
       "Time:                        17:48:53   Log-Likelihood:                -136.39\n",
       "No. Observations:                 100   AIC:                             276.8\n",
       "Df Residuals:                      98   BIC:                             282.0\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.0240      0.160     12.663      0.000       1.707       2.341\n",
       "X              0.5187      0.048     10.760      0.000       0.423       0.614\n",
       "==============================================================================\n",
       "Omnibus:                        1.283   Durbin-Watson:                   2.068\n",
       "Prob(Omnibus):                  0.527   Jarque-Bera (JB):                0.839\n",
       "Skew:                           0.200   Prob(JB):                        0.657\n",
       "Kurtosis:                       3.202   Cond. No.                         5.88\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Put your answer in this cell.\n",
    "\n",
    "## Taking random sample\n",
    "sample_df = df.sample(n=100, replace=True)\n",
    "\n",
    "\n",
    "## Running regression\n",
    "\n",
    "mod = sm.ols(\"Y ~ X\", data=sample_df)\n",
    "results = mod.fit()\n",
    "results.summary()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Which regression has a higher standard error for $\\hat{b}_1$ Why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "The regression with the lower sample size (in this case 1,000) will have the lower standard error."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Now let's see what happens when we keep sampling. This will allow us to construct a distribution for $\\hat{b}_1$. This will involve making a loop much like in HW2.\n",
    "\n",
    "Write a loop that loops over the many regressions and stores the results in a list. Run the loop 1000 times. Call this list `b_dist`.\n",
    "\n",
    "Instead of appending a number multiplied by another as in HW2, append `results.params['X']` (I'm assuming that you're using `results= mod.fit()`).\n",
    "\n",
    "Remember to put in a sample command in the loop, so that new data can be sampled every iteration.\n",
    "\n",
    "So your loop should look like this:\n",
    "\n",
    "```python\n",
    "b_dist = []\n",
    "\n",
    "for reg in <<the range from 0 to 1000>>:\n",
    "    \n",
    "    <<sampling command>>\n",
    "    <<regression commands>>\n",
    "    <<parameter appending to b_dist>>\n",
    "```\n",
    "    \n",
    "\n",
    "After the loop, make this list into a `pandas` dataframe and call it `b_dist_df`: `b_dist_df = pd.DataFrame({'b_dist':b_dist})`\n",
    "\n",
    "**Note: It might take a while.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T00:49:23.369240Z",
     "start_time": "2019-08-24T00:49:14.476997Z"
    }
   },
   "outputs": [],
   "source": [
    "## Put your answer in this cell.\n",
    "\n",
    "b_dist = []\n",
    "\n",
    "for reg in range(1000):\n",
    "    \n",
    "    sample_df = df.sample(n=100, replace=True)\n",
    "\n",
    "\n",
    "    mod = sm.ols(\"Y ~ X\", data=sample_df)\n",
    "    results = mod.fit()\n",
    "    b_dist.append(results.params['X'])\n",
    "\n",
    "b_dist_df = pd.DataFrame({'b_dist': b_dist})\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g.Now create a histogram of `b_dist` with:\n",
    "\n",
    "```python\n",
    "b_dist_df.hist()\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T00:48:26.470221Z",
     "start_time": "2019-08-24T00:48:26.238330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f4322ff53d0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "## Do not modify the above\n",
    "\n",
    "## Put your answer in this cell.\n",
    "\n",
    "b_dist_df.hist()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. What is the mean of `b_dist`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T00:48:26.476572Z",
     "start_time": "2019-08-24T00:48:26.472489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4964843177758095"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Put your answer in this cell.\\pagebreak\n",
    "\n",
    "\n",
    "b_dist_df['b_dist'].mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Plot a vertical line on the histogram, which denotes the population parameter, $\\beta_1$. To do this, you can do this:\n",
    "\n",
    "```python\n",
    "b_dist_df.hist()\n",
    "plt.axvline(<population parameter here>, color='red')\n",
    "```\n",
    "\n",
    "Does the OLS estimator seem unbiased? What would have made each estimate even closer to the population parameter? Write your answer in a print statement."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-24T00:48:26.732206Z",
     "start_time": "2019-08-24T00:48:26.493775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distribution is centered, more or less, around the population parameter.To make it better, we can try increasing the sample size of each random sample.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Put your answer in this cell.\n",
    "\n",
    "b_dist_df.hist()\n",
    "plt.axvline(0.5, color='red')\n",
    "\n",
    "print(\"The distribution is centered, more or less, around the population parameter.\\\n",
    "To make it better, we can try increasing the sample size of each random sample.\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
