{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARE 106 Summer Session II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "This homework will be due on **August 29th at 2pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSID: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please put your name and SSID in the corresponding cells above.\n",
    "\n",
    "The homework is worth 13.5 points.\n",
    "\n",
    "For each of the following questions, show as much of your steps as you can (without going overboard). If you end up getting the wrong answer, but we spot where you made a mistake in the algebra, partial credit will be more readily given. If you only put the final answer, you will be marked either right or wrong.\n",
    "\n",
    "Answer questions in the correct cell. For problems where you have to input math, make sure that you know that it's a markdown cell (It won't have a `In: []` on the left) and make sure you run the cell by either pressing `Ctrl + Enter` or going to `Cell -> Run Cell`. Alternatively, write all your answers and then go to `Cell -> Run All Cells` after you're done. \n",
    "\n",
    "Please ignore cells that read `\\pagebreak`. These are so your document converts to PDF in a way that will make it possible to grade your homework. Ignore them and only write your answers where it is specified.\n",
    "\n",
    "**When you are finished export your homework to a PDF by going to `File -> Download as -> PDF`.**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Single Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please don't forget to comment your code. Failure to do so will result in a loss of points.**\n",
    "\n",
    "Also remember that all code that is required here (unless otherwise stated) can be found in the lecture Jupyter Notebooks or the coding notebooks from class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are three models for the median starting salary of law school graduates in 1985.\n",
    "\n",
    "\n",
    "\\begin{gather}\n",
    "log(salary_i) = b_0 + b_1 LSAT_i + e_i \\\\\n",
    "log(salary_i) = b_0 + b_1 LSAT_i + b_2 GPA_i + e_i \\\\\n",
    "log(salary_i) = b_0 + b_1 LSAT_i + b_2 GPA_i + b_3 log(cost_i) + b_4 rank_i + e_i\n",
    "\\end{gather}\n",
    "    \n",
    "\t \n",
    "Each observation $i$ represents a school.\n",
    "\n",
    "The variables in the dataset are:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   | Variable           |   Description |\n",
    "|---------|---------------|---------------|\n",
    "|  1.     | rank               |law school ranking    |                        \n",
    "|  2.     | salary             |median starting salary|\n",
    "|  3.     | cost               |law school cost|\n",
    "|  4.     | LSAT               |median LSAT score|\n",
    "|  5.     | GPA                |median college GPA|\n",
    "|  6.     | libvol             |no. volumes in lib., 1000s|\n",
    "|  7.     | faculty            |no. of faculty|\n",
    "|  8.     | age                |age of law sch., years|\n",
    "|  9.     | clsize             |size of entering class|\n",
    "| 10.     | north              |=1 if law sch in north|\n",
    "| 11.     | south              |=1 if law sch in south|\n",
    "| 12.     | east               |=1 if law sch in east|\n",
    "| 13.     | west               |=1 if law sch in west|\n",
    "| 14.     | studfac            |student-faculty ratio|\n",
    "| 15.     | top10              |=1 if ranked in top 10|\n",
    "| 16.     | r11_25             |=1 if ranked 11-25|\n",
    "| 17.     | r26_40             |=1 if ranked 26-40|\n",
    "| 18.     | r41_60             |=1 if ranked 41-60|"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. In the code cell below, write the appropriate imports you will need for this question (we will need `pandas`, `numpy` and `statsmodels.formula.api`). You can do an abbreviated import if you wish (but the standard for `pandas` is `pd`, `statsmodels.formula.api` is `smf`, and `numpy` is `np`). Afterwards, load in the data from here:\n",
    "\n",
    "https://raw.githubusercontent.com/lordflaron/ARE106data/master/lawsch85.csv\n",
    "\n",
    "This can be done using the `read_csv()` function. Name this dataset `raw_df`. After loading in the data, show the first *10* observations in the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:56.534918Z",
     "start_time": "2019-09-03T07:48:56.047193Z"
    }
   },
   "outputs": [],
   "source": [
    "## a. Put your answer in this cell.\n",
    "\n",
    "## import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "## import data\n",
    "raw_df = pd.read_csv(\"https://raw.githubusercontent.com/lordflaron/ARE106data/master/lawsch85.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:56.924628Z",
     "start_time": "2019-09-03T07:48:56.537246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fad68f8cd10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.read_csv(\"https://raw.githubusercontent.com/lordflaron/ARE106data/master/lawsch85.csv\")\n",
    "\n",
    "raw_df[['salary', 'LSAT']].plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use the `describe()` method on `raw_df` to show a table of summary statistics for each variable in the dataset. How many observations does $salary_i$ have? Write this in a print statement. (Hint: This is in the \"count\" row the summary table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:56.979849Z",
     "start_time": "2019-09-03T07:48:56.927010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 156 observations in salary\n"
     ]
    }
   ],
   "source": [
    "## b. Put your answer in this cell.\n",
    "\n",
    "## describe the data\n",
    "raw_df.describe()\n",
    "\n",
    "print(\"there are 156 observations in salary\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Since we'll need a log-transformed version of $salary_i$ for all our models, use `assign()` to create a new variable which is the log of $salary_i$. Name this new variable `log_salary`.\n",
    "\n",
    "Hints:\n",
    "\n",
    "Remember that assign is not an *inplace* operation!\n",
    "\n",
    "Remember to use a lambda function in this case. To log a variable, you can use `np.log()`\n",
    "\n",
    "Remember the syntax for `assign()`:\n",
    "\n",
    "```\n",
    "my_df.assign(new_variable = expression)\n",
    "```\n",
    "\n",
    "After this we now need to also drop any observations that are missing. This isn't actually how econometricians deal with missing data, but this is good enough for us for now.\n",
    "\n",
    "You can do this by chaining the `dropna()` method after the `assign()` method.\n",
    "\n",
    "**Warning: Do not do `dropna` BEFORE `assign`**\n",
    "\n",
    "The end result should look something like this:\n",
    "\n",
    "```\n",
    "df = raw_df.assign(log_salary= expression).dropna()\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:56.990734Z",
     "start_time": "2019-09-03T07:48:56.982314Z"
    }
   },
   "outputs": [],
   "source": [
    "## c. Put your answer in this cell.\n",
    "df = raw_df.assign(log_salary = lambda x: np.log(x['salary'])).dropna()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Before estimating the model, explain how to interpret $b_1$ in Model 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for d here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "We interpret $b_1$ here as the effect of one extra unit of LSAT score on the log of median salary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Before estimating the model, explain how to interpret $b_1$ in Model 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for e here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "In this case, we interpret this as one extra unit of LSAT score on the log of median salary, *keeping GPA unchanged*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Before estimating the model, do you expect $b_1$ and $b_2$ to be positive or negative in Model 2?  Explain.\n",
    "(Hint: I'm not asking for any rigorous mathematical way to answer this question. Just use your economic intuition and reasoning skills to write an argument)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for f here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "It would make sense that since a higher LSAT score would lead to getting into a better law school and thus a higher median salary, The effect of LSAT should then probably be positive. Since a higher GPA would also lead to higher achievement in learning law, and excelling as a lawyer, we would also expect it to have a positive effect.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Estimate Model 1. Show the regression output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:57.515637Z",
     "start_time": "2019-09-03T07:48:57.486768Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>np.log(salary)</td>  <th>  R-squared:         </th> <td>   0.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   74.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>1.45e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:48:57</td>     <th>  Log-Likelihood:    </th> <td>  36.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>  -67.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    87</td>      <th>  BIC:               </th> <td>  -59.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    3.9650</td> <td>    0.711</td> <td>    5.577</td> <td> 0.000</td> <td>    2.552</td> <td>    5.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSAT</th>      <td>    0.0329</td> <td>    0.006</td> <td>    5.165</td> <td> 0.000</td> <td>    0.020</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GPA</th>       <td>    0.4152</td> <td>    0.141</td> <td>    2.955</td> <td> 0.004</td> <td>    0.136</td> <td>    0.695</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.974</td> <th>  Durbin-Watson:     </th> <td>   1.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.615</td> <th>  Jarque-Bera (JB):  </th> <td>   0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.170</td> <th>  Prob(JB):          </th> <td>   0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.183</td> <th>  Cond. No.          </th> <td>6.56e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.56e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         np.log(salary)   R-squared:                       0.631\n",
       "Model:                            OLS   Adj. R-squared:                  0.623\n",
       "Method:                 Least Squares   F-statistic:                     74.41\n",
       "Date:                Tue, 03 Sep 2019   Prob (F-statistic):           1.45e-19\n",
       "Time:                        00:48:57   Log-Likelihood:                 36.742\n",
       "No. Observations:                  90   AIC:                            -67.48\n",
       "Df Residuals:                      87   BIC:                            -59.99\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.9650      0.711      5.577      0.000       2.552       5.378\n",
       "LSAT           0.0329      0.006      5.165      0.000       0.020       0.046\n",
       "GPA            0.4152      0.141      2.955      0.004       0.136       0.695\n",
       "==============================================================================\n",
       "Omnibus:                        0.974   Durbin-Watson:                   1.857\n",
       "Prob(Omnibus):                  0.615   Jarque-Bera (JB):                0.559\n",
       "Skew:                          -0.170   Prob(JB):                        0.756\n",
       "Kurtosis:                       3.183   Cond. No.                     6.56e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.56e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## g. Put your answer in this cell.\n",
    "\n",
    "mod = smf.ols('np.log(salary) ~ LSAT + GPA', data=df) ## Like writing down the equation\n",
    "results = mod.fit() ## Like doing the minimization problem \n",
    "results.summary() ## Computing the numbers and showing in a table\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. What is the effect of a one unit increase in LSAT score on the log of median salary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for h here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "The effect is 0.0475\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. What does the $R^2$ measure in the regression? What is the $R^2$ in this case? (Not the adjusted $R^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for i here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "The $R^2$ measures how much of the variability in $log_salary$ is explained by the model. The $R^2$ in this case is 0.594\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Multiple Regression\n",
    "\n",
    "This is a continuation of what we were doing in Exercise 1.\n",
    "\n",
    "For this exercise, observe the expression for $b_1$ when there are two regressors in the equation:\n",
    "\n",
    "$$\n",
    "\\hat{b_1} = \\frac{\\sum_i^N x_{1i} y_i \\sum_i^N x_{2i}^2 - \\sum_i^N x_{1i} x_{2i} \\sum_i^N x_{2i} y_i}{\\sum_i^N x_{1i}^2 \\sum_i^N x_{2i}^2 - \\left(\\sum_i^N x_{1i} x_{2i} \\right)^2}\n",
    "$$\n",
    "\n",
    "Hint: Notice that each of these terms in the equation look similar to either covariances or variances (in fact if you multiply the denominator and numerator by $\\frac{1}{N^2}$ then they are in fact variances and covariances without changing the value of the coefficient (since $\\frac{\\frac{1}{N^2}}{\\frac{1}{N^2}}$ is 1).\n",
    "\n",
    "Also notice that the covariance is like an **un-normalized correlation coefficient**. So if you calculate the correlation between two variables, you won't know the covariance between the two, but you'll know the direction and strength of their relationship."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Estimate Model 2. Show the regression output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:58.322442Z",
     "start_time": "2019-09-03T07:48:58.293462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>log_salary</td>    <th>  R-squared:         </th> <td>   0.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   74.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>1.45e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:48:58</td>     <th>  Log-Likelihood:    </th> <td>  36.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>  -67.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    87</td>      <th>  BIC:               </th> <td>  -59.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    3.9650</td> <td>    0.711</td> <td>    5.577</td> <td> 0.000</td> <td>    2.552</td> <td>    5.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSAT</th>      <td>    0.0329</td> <td>    0.006</td> <td>    5.165</td> <td> 0.000</td> <td>    0.020</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GPA</th>       <td>    0.4152</td> <td>    0.141</td> <td>    2.955</td> <td> 0.004</td> <td>    0.136</td> <td>    0.695</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.974</td> <th>  Durbin-Watson:     </th> <td>   1.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.615</td> <th>  Jarque-Bera (JB):  </th> <td>   0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.170</td> <th>  Prob(JB):          </th> <td>   0.756</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.183</td> <th>  Cond. No.          </th> <td>6.56e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.56e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             log_salary   R-squared:                       0.631\n",
       "Model:                            OLS   Adj. R-squared:                  0.623\n",
       "Method:                 Least Squares   F-statistic:                     74.41\n",
       "Date:                Tue, 03 Sep 2019   Prob (F-statistic):           1.45e-19\n",
       "Time:                        00:48:58   Log-Likelihood:                 36.742\n",
       "No. Observations:                  90   AIC:                            -67.48\n",
       "Df Residuals:                      87   BIC:                            -59.99\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.9650      0.711      5.577      0.000       2.552       5.378\n",
       "LSAT           0.0329      0.006      5.165      0.000       0.020       0.046\n",
       "GPA            0.4152      0.141      2.955      0.004       0.136       0.695\n",
       "==============================================================================\n",
       "Omnibus:                        0.974   Durbin-Watson:                   1.857\n",
       "Prob(Omnibus):                  0.615   Jarque-Bera (JB):                0.559\n",
       "Skew:                          -0.170   Prob(JB):                        0.756\n",
       "Kurtosis:                       3.183   Cond. No.                     6.56e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.56e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## a. Put your answer in this cell.\n",
    "\n",
    "mod = smf.ols('log_salary ~ LSAT +GPA ', data=df) ## Like writing down the equation\n",
    "results = mod.fit() ## Like doing the minimization problem \n",
    "results.summary() ## Computing the numbers and showing in a table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Calculate the correlations between $log(salary)_i$, $LSAT_i$ and $GPA_i$.\n",
    "\n",
    "Use the slicing notation to first make a subset of the data with only log_salary, LSAT and GPA.\n",
    "\n",
    "Then use the `corr()` method to get the correlation for those variables, i.e. it will look something like this:\n",
    "\n",
    "`df[['log_salary', 'GPA', 'LSAT']].corr()`\n",
    "\n",
    "This will give a matrix where you can see correlation between variables. (Note: correlation of a variable with itself is always 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:58.477453Z",
     "start_time": "2019-09-03T07:48:58.461817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_salary</th>\n",
       "      <th>GPA</th>\n",
       "      <th>LSAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log_salary</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719707</td>\n",
       "      <td>0.770756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPA</th>\n",
       "      <td>0.719707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.776454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSAT</th>\n",
       "      <td>0.770756</td>\n",
       "      <td>0.776454</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            log_salary       GPA      LSAT\n",
       "log_salary    1.000000  0.719707  0.770756\n",
       "GPA           0.719707  1.000000  0.776454\n",
       "LSAT          0.770756  0.776454  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## b. Put your answer in this cell.\n",
    "\n",
    "## Calculating correlation matrix\n",
    "df[['log_salary', 'GPA', 'LSAT']].corr()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Using you answer from (b) and the expression for $\\hat{b_1}$ above, answer this question:\n",
    "\n",
    "Why is $b_1$ in Model 2 different from $b_1$ in Model 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for c here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "In this case since the correlations between $GPA$ and $LSAT$ are positive and $GPA$ and $log_salary$ is positive, this leads to lowering the coefficient on $LSAT$ to 0.0329.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Why is the $R^2$ in Model 2 higher than Model 1? (Not the adjusted $R^2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for d here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "Since we added more coefficients to the model, the $R^2$ has gone up to 0.631\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Estimate Model 3. Show the regression output.\n",
    "\n",
    "Hint: One of the extra regressors in Model 3 is log-transformed. Instead of doing another `assign()` call, run this regression by explicitly logging the variable in the `patsy` formula. Use `np.log()` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:59.105584Z",
     "start_time": "2019-09-03T07:48:59.050536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>log_salary</td>    <th>  R-squared:         </th> <td>   0.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   96.24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>9.80e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:48:59</td>     <th>  Log-Likelihood:    </th> <td>  68.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>  -127.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    85</td>      <th>  BIC:               </th> <td>  -115.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>    8.0511</td> <td>    0.709</td> <td>   11.360</td> <td> 0.000</td> <td>    6.642</td> <td>    9.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSAT</th>         <td>    0.0097</td> <td>    0.006</td> <td>    1.710</td> <td> 0.091</td> <td>   -0.002</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>GPA</th>          <td>    0.2430</td> <td>    0.119</td> <td>    2.044</td> <td> 0.044</td> <td>    0.007</td> <td>    0.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>np.log(cost)</th> <td>    0.0459</td> <td>    0.042</td> <td>    1.098</td> <td> 0.275</td> <td>   -0.037</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank</th>         <td>   -0.0034</td> <td>    0.000</td> <td>   -7.939</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.199</td> <th>  Durbin-Watson:     </th> <td>   1.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.905</td> <th>  Jarque-Bera (JB):  </th> <td>   0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.021</td> <th>  Prob(JB):          </th> <td>   0.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.050</td> <th>  Cond. No.          </th> <td>1.03e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.03e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             log_salary   R-squared:                       0.819\n",
       "Model:                            OLS   Adj. R-squared:                  0.811\n",
       "Method:                 Least Squares   F-statistic:                     96.24\n",
       "Date:                Tue, 03 Sep 2019   Prob (F-statistic):           9.80e-31\n",
       "Time:                        00:48:59   Log-Likelihood:                 68.820\n",
       "No. Observations:                  90   AIC:                            -127.6\n",
       "Df Residuals:                      85   BIC:                            -115.1\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept        8.0511      0.709     11.360      0.000       6.642       9.460\n",
       "LSAT             0.0097      0.006      1.710      0.091      -0.002       0.021\n",
       "GPA              0.2430      0.119      2.044      0.044       0.007       0.479\n",
       "np.log(cost)     0.0459      0.042      1.098      0.275      -0.037       0.129\n",
       "rank            -0.0034      0.000     -7.939      0.000      -0.004      -0.003\n",
       "==============================================================================\n",
       "Omnibus:                        0.199   Durbin-Watson:                   1.795\n",
       "Prob(Omnibus):                  0.905   Jarque-Bera (JB):                0.016\n",
       "Skew:                          -0.021   Prob(JB):                        0.992\n",
       "Kurtosis:                       3.050   Cond. No.                     1.03e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.03e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## e. Put your answer in this cell.\n",
    "\n",
    "mod = smf.ols('log_salary ~ LSAT +GPA +np.log(cost) + rank', data=df) ## Like writing down the equation\n",
    "results = mod.fit() ## Like doing the minimization problem \n",
    "results.summary() ## Computing the numbers and showing in a table\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Suppose School A and School B have the same values for all the variables on the right hand side in Model 3, except School A is ranked 10 places higher than School B. What is the predicted difference in log median salary between the two schools?\n",
    "\n",
    "This question can be answered by simply printing out the math you did in a print statement using an `f-string`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:59.221378Z",
     "start_time": "2019-09-03T07:48:59.217839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It would be 0.033999999999999996\n"
     ]
    }
   ],
   "source": [
    "## f. Put your answer in this cell.\n",
    "\n",
    "print(f\"It would be {-10*(-.0034)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Multicollinearity\n",
    "\n",
    "a. Re-estimate Model 1, except add north, south, east, and west as the additional right hand side variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:59.407720Z",
     "start_time": "2019-09-03T07:48:59.368398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>log_salary</td>    <th>  R-squared:         </th> <td>   0.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   31.53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Sep 2019</td> <th>  Prob (F-statistic):</th> <td>4.27e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:48:59</td>     <th>  Log-Likelihood:    </th> <td>  32.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>  -55.61</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    85</td>      <th>  BIC:               </th> <td>  -43.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.5155</td> <td>    0.557</td> <td>    4.515</td> <td> 0.000</td> <td>    1.408</td> <td>    3.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSAT</th>      <td>    0.0467</td> <td>    0.004</td> <td>   10.639</td> <td> 0.000</td> <td>    0.038</td> <td>    0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>north</th>     <td>    0.6215</td> <td>    0.147</td> <td>    4.232</td> <td> 0.000</td> <td>    0.329</td> <td>    0.914</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>west</th>      <td>    0.6256</td> <td>    0.143</td> <td>    4.384</td> <td> 0.000</td> <td>    0.342</td> <td>    0.909</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>     <td>    0.6148</td> <td>    0.135</td> <td>    4.548</td> <td> 0.000</td> <td>    0.346</td> <td>    0.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>east</th>      <td>    0.6536</td> <td>    0.147</td> <td>    4.437</td> <td> 0.000</td> <td>    0.361</td> <td>    0.947</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.212</td> <th>  Durbin-Watson:     </th> <td>   1.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.545</td> <th>  Jarque-Bera (JB):  </th> <td>   0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.015</td> <th>  Prob(JB):          </th> <td>   0.714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.423</td> <th>  Cond. No.          </th> <td>2.09e+18</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.16e-31. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             log_salary   R-squared:                       0.597\n",
       "Model:                            OLS   Adj. R-squared:                  0.578\n",
       "Method:                 Least Squares   F-statistic:                     31.53\n",
       "Date:                Tue, 03 Sep 2019   Prob (F-statistic):           4.27e-16\n",
       "Time:                        00:48:59   Log-Likelihood:                 32.806\n",
       "No. Observations:                  90   AIC:                            -55.61\n",
       "Df Residuals:                      85   BIC:                            -43.11\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.5155      0.557      4.515      0.000       1.408       3.623\n",
       "LSAT           0.0467      0.004     10.639      0.000       0.038       0.055\n",
       "north          0.6215      0.147      4.232      0.000       0.329       0.914\n",
       "west           0.6256      0.143      4.384      0.000       0.342       0.909\n",
       "south          0.6148      0.135      4.548      0.000       0.346       0.884\n",
       "east           0.6536      0.147      4.437      0.000       0.361       0.947\n",
       "==============================================================================\n",
       "Omnibus:                        1.212   Durbin-Watson:                   1.897\n",
       "Prob(Omnibus):                  0.545   Jarque-Bera (JB):                0.675\n",
       "Skew:                          -0.015   Prob(JB):                        0.714\n",
       "Kurtosis:                       3.423   Cond. No.                     2.09e+18\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.16e-31. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Exercise 3. Put your answer in this cell.\n",
    "\n",
    "mod = smf.ols('log_salary ~ LSAT +north+west+south+east ', data=df) ## Like writing down the equation\n",
    "results = mod.fit() ## Like doing the minimization problem \n",
    "results.summary() ## Computing the numbers and showing in a table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.  What is wrong with this regression? What happens when you estimate it? How could fix this problem?\n",
    "\n",
    "Hint: Look at the warnings underneath the regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for b here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "The warnings tell us that there is evidence of multicollinearity. This is due to the fact that we have included all four types of direction variables and we know that $north+west+east+south=1$. A way to fix this problem would be to omit one of these variables.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Auxiliary Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following two regressions:\n",
    "\n",
    "\\begin{gather*}\n",
    "    LSAT_i = a_0 + a_1 GPA_i + v_i \\\\ \n",
    "    log(salary_i) = b_0 + b_1 v_i + e_i \n",
    "\\end{gather*}\n",
    "\n",
    "a. Estimate $b_1$. This is a two-step process. First, you need to estimate the first regression model and save the errors. Then, you regress $log(salary_i)$ on those errors ($v_i$). Compare your estimate of $b_1$ to the estimate you found from Model 2. Explain the similarity or difference. \n",
    "\n",
    "In order to do this, you need to save the errors (also called residuals) after you run the first stage. In order to do this, after fitting the first stage, the `results` variable will have an attribute `resid`. So to call the residuals all you need to do is type this: `results.resid`. \n",
    "\n",
    "You can then run the second stage in one of two ways:\n",
    "\n",
    "- 1. `assign` a new variable to your data, called \"residuals\" and run a regresion with it like any other variable, or\n",
    "- 2. Directly call `results.resid` in your second stage's `patsy formula`, i.e, ` 'log_salary ~ results.resid'`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T07:48:59.877022Z",
     "start_time": "2019-09-03T07:48:59.838509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>log_salary</td>    <th>  R-squared:         </th> <td>   0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   11.22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 03 Sep 2019</td> <th>  Prob (F-statistic):</th>  <td>0.00119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>00:48:59</td>     <th>  Log-Likelihood:    </th> <td> -2.7297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    90</td>      <th>  AIC:               </th> <td>   9.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    88</td>      <th>  BIC:               </th> <td>   14.46</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>   10.5537</td> <td>    0.027</td> <td>  396.926</td> <td> 0.000</td> <td>   10.501</td> <td>   10.607</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>results.resid</th> <td>    0.0329</td> <td>    0.010</td> <td>    3.350</td> <td> 0.001</td> <td>    0.013</td> <td>    0.052</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 8.095</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.017</td> <th>  Jarque-Bera (JB):  </th> <td>   8.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.726</td> <th>  Prob(JB):          </th> <td>  0.0141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.597</td> <th>  Cond. No.          </th> <td>    2.71</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             log_salary   R-squared:                       0.113\n",
       "Model:                            OLS   Adj. R-squared:                  0.103\n",
       "Method:                 Least Squares   F-statistic:                     11.22\n",
       "Date:                Tue, 03 Sep 2019   Prob (F-statistic):            0.00119\n",
       "Time:                        00:48:59   Log-Likelihood:                -2.7297\n",
       "No. Observations:                  90   AIC:                             9.459\n",
       "Df Residuals:                      88   BIC:                             14.46\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept        10.5537      0.027    396.926      0.000      10.501      10.607\n",
       "results.resid     0.0329      0.010      3.350      0.001       0.013       0.052\n",
       "==============================================================================\n",
       "Omnibus:                        8.095   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.017   Jarque-Bera (JB):                8.517\n",
       "Skew:                           0.726   Prob(JB):                       0.0141\n",
       "Kurtosis:                       2.597   Cond. No.                         2.71\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## a. Put your answer in this cell.\n",
    "\n",
    "## First stage regression\n",
    "mod = smf.ols('LSAT ~ GPA', data=df) \n",
    "results = mod.fit() \n",
    "\n",
    "## Second stage regression using residuals from first stage.\n",
    "results.summary()\n",
    "mod2 = smf.ols('log_salary ~ results.resid', data=df)\n",
    "mod2.fit().summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. What do you notice from the coefficient on this regression, versus the one in Model 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for b here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "The coefficient on this regression is the same as $b_1$ from model 1."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Back to $R^2$\n",
    "\n",
    "Suppose that we have an estimated regression model $y_i = \\hat{b}_0 + \\hat{b}_1 x_i +e_i$, where $\\hat{b}_0,\\hat{b}_1$ are estimated OLS coefficients. Let $\\hat{y}_i = \\hat{b}_0 + \\hat{b}_1 x_i$, so that:\n",
    "\n",
    "$$\n",
    "y_i = \\hat{y}_i + e_i\n",
    "$$\n",
    "\n",
    "Let's look at the next step of solving this problem in order to finally get at solving a mystery we've had during the class. \n",
    "\n",
    "If we wanted to solve for the $R^2$, we would use the fact that a way to understand the variability in $y_i$ is to look at its variance. And we already know that:\n",
    "\n",
    "$$\n",
    "Var(y_i) = Var(\\hat{y_i} + e_i) = Var(\\hat{y_i}) + Var(e_i) + 2Cov(\\hat{y_i}, e_i)\n",
    "$$\n",
    "\n",
    "Up until now, we've just assumed it to be true that $Cov(\\hat{y_i}, e_i)$ was 0 and it allowed us to finish the proof. But all along, we've been implicitly assuming a Gauss-Markov assumption in order to make that claim.\n",
    "\n",
    "Which of the Gauss-Markov assumptions do we need in order to say that $Cov(\\hat{y_i}, e_i)=0$?\n",
    "\n",
    "**Hint: Don't forget that you can express the covariance in terms of expectations.**\n",
    "\n",
    "**Hint: Try plugging in $\\hat{y}_i = \\hat{b}_0 + \\hat{b}_1 x_i$ into this expression and seeing what you end up with.**\n",
    "\n",
    "**Hint: Don't forget that $\\sum_i^N e_i=0$**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for exercise 5 here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "We can rewrite the the covariance like so:\n",
    "\n",
    "$$\n",
    "Cov(\\hat{y_i}, e_i) = E\\left[(\\hat{y_i} - \\bar{y})(e_i - \\bar{e})\\right]\n",
    "$$\n",
    "\n",
    "Knowing that $\\bar{e}=0$, we can see that:\n",
    "\n",
    "$$\n",
    "Cov(\\hat{y_i}, e_i) = E(\\hat{y_i}e_i) -E(\\bar{y}e_i)\n",
    "$$\n",
    "\n",
    "Since we know that $\\bar{y}E(e_i)=0$, we can plug in $\\hat{y_i}$ into the rest and get:\n",
    "\n",
    "$$\n",
    "Cov(\\hat{y_i}, e_i) = E((\\hat{b_0} + \\hat{b_1} x_i)e_i)\n",
    "$$\n",
    "\n",
    "Distributing $e_i$ and the expectation operator brings us to:\n",
    "\n",
    "$$\n",
    "Cov(\\hat{y_i}, e_i) = E(\\hat{b_0} e_i) + E(\\hat{b_1} x_i e_i)\n",
    "$$\n",
    "\n",
    "Again, we know that $\\hat{b_0}E(e_i)=0$, so we are left with:\n",
    "\n",
    "$$\n",
    "Cov(\\hat{y_i}, e_i) = \\hat{b_1}E(x_i e_i)\n",
    "$$\n",
    "\n",
    "From CR5, we know that $E(x_i e_i)=0$, so we are done."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we have a population model:\n",
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X + \\epsilon\n",
    "$$\n",
    "\n",
    "The subscripts for the variables have been purposely omitted. For each part, rewrite the model so that it corresponds to each data type and explain why you wrote it that way.\n",
    "\n",
    "- a. Cross-section\n",
    "- b. Time Series\n",
    "- c. Panel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\pagebreak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please write your answer for exercise 6 here. If you need to use more than one line, you may do so.**\n",
    "\n",
    "- a. In this case, we have $Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i$, where we are following several subjects $i$ in a given time.\n",
    "- b. Here we have $Y_t = \\beta_0 + \\beta_1 X_t + \\epsilon_t$, so we are following the same subject across time.\n",
    "- c. Now we have $Y_{it} = \\beta_0 + \\beta_1 X_{it} + \\epsilon_{it}$, where we are following several subjects across time.\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
